{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdb433791d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train data \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "#Load test data \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=enumerate(train_loader)\n",
    "batch_index,(example_data,example_target)=next(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fdb42ff8e48>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Visualize the data \n",
    "fig=plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0],cmap='gray',interpolation='none')\n",
    "    plt.title(\"Ground Truth:{}\".format(example_target[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop=nn.Dropout2d()\n",
    "        self.fc1=nn.Linear(320,50)\n",
    "        self.fc2=nn.Linear(50,10)\n",
    "    def forward(self,x): \n",
    "        x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x=x.view(-1,320)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=Net()\n",
    "optimizer=optim.SGD(network.parameters(),lr=learning_rate,momentum=momentum)#stochastic optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "train_counter=[]\n",
    "test_counter=[i*len(train_loader.dataset) for i in range(n_epochs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        torch.save(network.state_dict(), './model.pth')\n",
    "        torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_counter.append((data*1000) + ((data-1)*len(test_loader.dataset)))\n",
    "    torch.save(network.state_dict(), './model.pth')\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n",
      "/home/aims/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.163815\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.154027\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.229586\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.170768\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.179560\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.153753\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.086534\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.068130\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.133579\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.156082\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.189213\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.302795\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.203012\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.294490\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.105945\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.229359\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.209955\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.189319\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.203950\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.149408\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.150571\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.221005\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.171139\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.268495\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.233823\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.195166\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.244757\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.318265\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.215646\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.106762\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.054215\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.182926\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.134177\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.032173\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.195929\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.088005\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.232503\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.051468\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.128253\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.075127\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.151690\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.373401\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.210893\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.201937\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.053864\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.087146\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.209256\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.050113\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.109540\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.120453\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.186546\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.213047\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.277939\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.082752\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.154663\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.054258\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.109858\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.185884\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.188350\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.195287\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.356378\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.161445\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.091881\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.110688\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.226031\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.247491\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.200612\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.144290\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.118803\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.252721\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.054857\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.264333\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.191416\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.097625\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.108820\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.164091\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.135034\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.162446\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.136224\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.130071\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.169746\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.236671\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.301963\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.152710\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.264050\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.127258\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.080142\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.317905\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.210419\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.448680\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.254498\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.046756\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.080342\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.156175\n",
      "\n",
      "Test set: Avg. loss: 0.0537, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.140864\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.390413\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.138945\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.094986\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.091639\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.161224\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.255417\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.154489\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.091478\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.299816\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.241744\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.286492\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.100749\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.264678\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.199390\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.293511\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.154583\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.260660\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.095179\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.090857\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.119542\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.238399\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.174945\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.154161\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.314261\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.187258\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.222662\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.274922\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.147469\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.346307\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.102617\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.330767\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.269386\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.181868\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.202070\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.213532\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.088115\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.111290\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.150784\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.165875\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.120512\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.212929\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.116246\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.169123\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.069954\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.179686\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.097662\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.087626\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.108459\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.136472\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.184228\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.119551\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.148841\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.094452\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.165739\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.105872\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.147535\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.281849\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.164316\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.084385\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.078800\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.110306\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.207032\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.177570\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.125362\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.057120\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.261923\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.272383\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.196767\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.213641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.200701\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.046663\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.103039\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.261036\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.128040\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.080902\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.160161\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.146352\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.150399\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.189471\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.180953\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.167651\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.336338\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.142660\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.449889\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.056707\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.063162\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.085456\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.114843\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.139501\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.229203\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.142414\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.168786\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.187499\n",
      "\n",
      "Test set: Avg. loss: 0.0493, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.237390\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.062188\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.060601\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.395945\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.135695\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.131343\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.114671\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.104048\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.079454\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.162450\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.266145\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.257634\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.164157\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.228423\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.138571\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.251825\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.471047\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.193332\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.185190\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.144425\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.249266\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.116128\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.162988\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.151898\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.119451\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.061009\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.186030\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.056054\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.095850\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.130740\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.158105\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.116742\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.075703\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.121495\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.275734\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.138872\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.280151\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.145989\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.377106\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.298121\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.150160\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.044418\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.102062\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.218607\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.224085\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.113735\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.054927\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.226849\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.285280\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.122545\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.090160\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.062060\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.223910\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.119530\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.327301\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.059322\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.153103\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.104740\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.258305\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.148979\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.064602\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.147423\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.105480\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.156150\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.290045\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.050935\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.112334\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.129655\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.215164\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.085731\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.188030\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.136604\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.190772\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.119662\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.207512\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.512498\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.096611\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.050615\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.137759\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.069492\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.061682\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.057817\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.103519\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.246251\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.244299\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.092546\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.071502\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.100984\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.191041\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.252299\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.126451\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.208703\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.114125\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.235195\n",
      "\n",
      "Test set: Avg. loss: 0.0498, Accuracy: 9853/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    train(epoch)\n",
    "    a=test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
